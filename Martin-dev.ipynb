{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os \n",
    "import pickle\n",
    "import argparse\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import sklearn\n",
    "import torch\n",
    "import datetime\n",
    "import matplotlib, matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "import academictorrents as at\n",
    "import zipfile\n",
    "import json\n",
    "\n",
    "os.chdir(\"gene-graph-conv\")\n",
    "from models.model_wrapper import WrappedModel\n",
    "from data import datasets\n",
    "from data.graph_wrapper import GeneManiaGraph\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdmolops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for pieces on disk: |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.0%  finished\n",
      "/Users/martinweiss/code/academic/ICLR-reproducibility-challenge-2019/datastore/250k_rndm_zinc_drugs_clean.zip\n",
      "File Name                                             Modified             Size\n",
      "250k_rndm_zinc_drugs_clean_3.csv               2018-11-15 18:20:02     22606589\n",
      "__MACOSX/                                      2018-11-16 08:01:40            0\n",
      "__MACOSX/._250k_rndm_zinc_drugs_clean_3.csv    2018-11-15 18:20:02          280\n",
      "molecules_train_zinc.json                      2018-11-15 18:28:22    323265893\n",
      "molecules_valid_zinc.json                      2018-11-15 18:29:10     35921095\n",
      "smiles_zinc.pkl                                2018-11-15 18:28:22     10599265\n",
      "valid_idx_qm9.json                             2018-11-15 17:02:20       130846\n",
      "valid_idx_zinc.json                            2018-11-15 17:02:20       187832\n"
     ]
    }
   ],
   "source": [
    "# I uploaded the ZINC dataset to AcademicTorrents. This code should download it for you.\n",
    "path = at.get(\"4776b264ca3c4ed05530124b6319ce0d45aff626\")\n",
    "print(path)\n",
    "zip_ref = zipfile.ZipFile(path)\n",
    "zip_ref.extractall(\"datastore/\")\n",
    "zip_ref.printdir()\n",
    "zip_ref.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datastore/molecules_valid_zinc.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['node_features', 'graph', 'smiles', 'targets'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'N#Cc1ccc(-c2ccc(O[C@@H](C(=O)N3CCCC3)c3ccccc3)cc2)cc1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].get(\"smiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].get(\"node_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.599681738168]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].get(\"targets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0, 2, 1],\n",
       " [1, 0, 2],\n",
       " [2, 1, 3],\n",
       " [3, 0, 4],\n",
       " [4, 1, 5],\n",
       " [5, 0, 6],\n",
       " [6, 1, 7],\n",
       " [7, 0, 8],\n",
       " [8, 1, 9],\n",
       " [9, 0, 10],\n",
       " [10, 0, 11],\n",
       " [11, 0, 12],\n",
       " [12, 1, 13],\n",
       " [12, 0, 14],\n",
       " [14, 0, 15],\n",
       " [15, 0, 16],\n",
       " [16, 0, 17],\n",
       " [17, 0, 18],\n",
       " [11, 0, 19],\n",
       " [19, 1, 20],\n",
       " [20, 0, 21],\n",
       " [21, 1, 22],\n",
       " [22, 0, 23],\n",
       " [23, 1, 24],\n",
       " [9, 0, 25],\n",
       " [25, 1, 26],\n",
       " [5, 0, 27],\n",
       " [27, 1, 28],\n",
       " [28, 0, 2],\n",
       " [26, 0, 6],\n",
       " [18, 0, 14],\n",
       " [24, 0, 19]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.array(data[0]['graph']).shape)\n",
    "data[0].get(\"graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is just me sanity checking their pipeline.\n",
    "# the graphs in the json really do correspond to the smiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_NUMBER = 1e-7\n",
    "LARGE_NUMBER= 1e10\n",
    "\n",
    "geometry_numbers=[3, 4, 5, 6] # triangle, square, pentagen, hexagon\n",
    "\n",
    "# bond mapping\n",
    "bond_dict = {'SINGLE': 0, 'DOUBLE': 1, 'TRIPLE': 2, \"AROMATIC\": 3}\n",
    "number_to_bond= {0: Chem.rdchem.BondType.SINGLE, 1:Chem.rdchem.BondType.DOUBLE, \n",
    "                 2: Chem.rdchem.BondType.TRIPLE, 3:Chem.rdchem.BondType.AROMATIC}\n",
    "\n",
    "def to_graph(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return [], []\n",
    "    # Kekulize it\n",
    "    if need_kekulize(mol):\n",
    "        rdmolops.Kekulize(mol)\n",
    "        if mol is None:\n",
    "            return None, None\n",
    "    # remove stereo information, such as inward and outward edges\n",
    "    Chem.RemoveStereochemistry(mol)\n",
    "\n",
    "    edges = []\n",
    "    nodes = []\n",
    "    for bond in mol.GetBonds():\n",
    "        edges.append((bond.GetBeginAtomIdx(), bond_dict[str(bond.GetBondType())], bond.GetEndAtomIdx()))\n",
    "        assert bond_dict[str(bond.GetBondType())] != 3\n",
    "    for atom in mol.GetAtoms():\n",
    "        symbol = atom.GetSymbol()\n",
    "        valence = atom.GetTotalValence()\n",
    "        charge = atom.GetFormalCharge()\n",
    "        atom_str = \"%s%i(%i)\" % (symbol, valence, charge)\n",
    "\n",
    "        if atom_str not in dataset_info()['atom_types']:\n",
    "            print('unrecognized atom type %s' % atom_str)\n",
    "            return [], []\n",
    "\n",
    "        nodes.append(onehot(dataset_info()['atom_types'].index(atom_str), len(dataset_info()['atom_types'])))\n",
    "\n",
    "    return nodes, edges\n",
    "\n",
    "\n",
    "def need_kekulize(mol):\n",
    "    for bond in mol.GetBonds():\n",
    "        if bond_dict[str(bond.GetBondType())] >= 3:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def dataset_info():\n",
    "    return { 'atom_types': ['Br1(0)', 'C4(0)', 'Cl1(0)', 'F1(0)', 'H1(0)', 'I1(0)',\n",
    "            'N2(-1)', 'N3(0)', 'N4(1)', 'O1(-1)', 'O2(0)', 'S2(0)','S4(0)', 'S6(0)'],\n",
    "             'maximum_valence': {0: 1, 1: 4, 2: 1, 3: 1, 4: 1, 5:1, 6:2, 7:3, 8:4, 9:1, 10:2, 11:2, 12:4, 13:6, 14:3},\n",
    "             'number_to_atom': {0: 'Br', 1: 'C', 2: 'Cl', 3: 'F', 4: 'H', 5:'I', 6:'N', 7:'N', 8:'N', 9:'O', 10:'O', 11:'S', 12:'S', 13:'S'},\n",
    "             'bucket_sizes': np.array([28,31,33,35,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,53,55,58,84])\n",
    "           }\n",
    "\n",
    "def onehot(idx, len):\n",
    "    z = [0 for _ in range(len)]\n",
    "    z[idx] = 1\n",
    "    return z\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       " [(0, 2, 1),\n",
       "  (1, 0, 2),\n",
       "  (2, 1, 3),\n",
       "  (3, 0, 4),\n",
       "  (4, 1, 5),\n",
       "  (5, 0, 6),\n",
       "  (6, 1, 7),\n",
       "  (7, 0, 8),\n",
       "  (8, 1, 9),\n",
       "  (9, 0, 10),\n",
       "  (10, 0, 11),\n",
       "  (11, 0, 12),\n",
       "  (12, 1, 13),\n",
       "  (12, 0, 14),\n",
       "  (14, 0, 15),\n",
       "  (15, 0, 16),\n",
       "  (16, 0, 17),\n",
       "  (17, 0, 18),\n",
       "  (11, 0, 19),\n",
       "  (19, 1, 20),\n",
       "  (20, 0, 21),\n",
       "  (21, 1, 22),\n",
       "  (22, 0, 23),\n",
       "  (23, 1, 24),\n",
       "  (9, 0, 25),\n",
       "  (25, 1, 26),\n",
       "  (5, 0, 27),\n",
       "  (27, 1, 28),\n",
       "  (28, 0, 2),\n",
       "  (26, 0, 6),\n",
       "  (18, 0, 14),\n",
       "  (24, 0, 19)])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_graph(data[0].get(\"smiles\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Potentially useful functions I yinged from the microsoft code. Currently unused.\n",
    "def dump(file_name, content):\n",
    "    with open(file_name, 'wb') as out_file:        \n",
    "        pickle.dump(content, out_file, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "def load(file_name):\n",
    "    with open(file_name, 'rb') as f:\n",
    "        return pickle.load(f)    \n",
    "# add one edge to adj matrix\n",
    "def add_edge_mat(amat, src, dest, e, considering_edge_type=True):\n",
    "    if considering_edge_type:\n",
    "        amat[e, dest, src] = 1\n",
    "        amat[e, src, dest] = 1\n",
    "    else:\n",
    "        amat[src, dest] = 1\n",
    "        amat[dest, src] = 1 \n",
    "\n",
    "def graph_to_adj_mat(graph, max_n_vertices, num_edge_types, tie_fwd_bkwd=True, considering_edge_type=True):\n",
    "    if considering_edge_type:\n",
    "        amat = np.zeros((num_edge_types, max_n_vertices, max_n_vertices))\n",
    "        for src, e, dest in graph:\n",
    "            add_edge_mat(amat, src, dest, e)\n",
    "    else:\n",
    "        amat = np.zeros((max_n_vertices, max_n_vertices))\n",
    "        for src, e, dest in graph:\n",
    "            add_edge_mat(amat, src, dest, e, considering_edge_type=False)\n",
    "    return amat\n",
    "\n",
    "def check_validity(dataset):       \n",
    "    with open('generated_smiles_%s' % dataset, 'rb') as f:\n",
    "        all_smiles=set(pickle.load(f))\n",
    "    count=0\n",
    "    for smiles in all_smiles:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is not None:\n",
    "            count+=1\n",
    "    return len(all_smiles), count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sascorer(dataset):\n",
    "    with open('generated_smiles_%s' % dataset, 'rb') as f:   \n",
    "        all_smiles=set(pickle.load(f))     \n",
    "    sa_sum=0\n",
    "    total=0\n",
    "    sa_score_per_molecule=[]\n",
    "    for smiles in all_smiles:\n",
    "        new_mol=Chem.MolFromSmiles(smiles)\n",
    "        try:\n",
    "            val = sascorer.calculateScore(new_mol)\n",
    "        except:\n",
    "            continue\n",
    "        sa_sum+=val\n",
    "        sa_score_per_molecule.append(val)\n",
    "        total+=1\n",
    "    return sa_sum/total, sa_score_per_molecule\n",
    "\n",
    "def check_logp(dataset):\n",
    "    with open('generated_smiles_%s' % dataset, 'rb') as f:   \n",
    "        all_smiles=set(pickle.load(f))\n",
    "    logp_sum=0\n",
    "    total=0\n",
    "    logp_score_per_molecule=[]\n",
    "    for smiles in all_smiles:\n",
    "        new_mol=Chem.MolFromSmiles(smiles)\n",
    "        try:\n",
    "            val = Crippen.MolLogP(new_mol)\n",
    "        except:\n",
    "            continue\n",
    "        logp_sum+=val\n",
    "        logp_score_per_molecule.append(val)\n",
    "        total+=1\n",
    "    return logp_sum/total, logp_score_per_molecule\n",
    "\n",
    "def check_qed(dataset):\n",
    "    with open('generated_smiles_%s' % dataset, 'rb') as f:   \n",
    "        all_smiles=set(pickle.load(f))\n",
    "    qed_sum=0\n",
    "    total=0\n",
    "    qed_score_per_molecule=[]\n",
    "    for smiles in all_smiles:\n",
    "        new_mol=Chem.MolFromSmiles(smiles)\n",
    "        try:\n",
    "            val = QED.qed(new_mol)\n",
    "        except:\n",
    "            continue\n",
    "        qed_sum+=val\n",
    "        qed_score_per_molecule.append(val)\n",
    "        total+=1\n",
    "    return qed_sum/total, qed_score_per_molecule\n",
    "\n",
    "def sssr_metric(dataset):\n",
    "    with open('generated_smiles_%s' % dataset, 'rb') as f:   \n",
    "        all_smiles=set(pickle.load(f))\n",
    "    overlapped_molecule=0\n",
    "    for smiles in all_smiles:\n",
    "        new_mol=Chem.MolFromSmiles(smiles)\n",
    "        ssr = Chem.GetSymmSSSR(new_mol)\n",
    "        overlap_flag=False\n",
    "        for idx1 in range(len(ssr)):\n",
    "            for idx2 in range(idx1+1, len(ssr)):\n",
    "                if len(set(ssr[idx1]) & set(ssr[idx2])) > 2:\n",
    "                    overlap_flag=True\n",
    "        if overlap_flag:\n",
    "            overlapped_molecule+=1\n",
    "    return overlapped_molecule/len(all_smiles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implements multilayer perceptron\n",
    "class MLP(object):\n",
    "    def __init__(self, in_size, out_size, hid_sizes, dropout_keep_prob):\n",
    "        self.in_size = in_size\n",
    "        self.out_size = out_size\n",
    "        self.hid_sizes = hid_sizes\n",
    "        self.dropout_keep_prob = dropout_keep_prob\n",
    "        self.params = self.make_network_params()\n",
    "\n",
    "    def make_network_params(self):\n",
    "        dims = [self.in_size] + self.hid_sizes + [self.out_size]\n",
    "        weight_sizes = list(zip(dims[:-1], dims[1:]))\n",
    "        weights = [tf.Variable(self.init_weights(s), name='MLP_W_layer%i' % i)\n",
    "                   for (i, s) in enumerate(weight_sizes)]\n",
    "        biases = [tf.Variable(np.zeros(s[-1]).astype(np.float32), name='MLP_b_layer%i' % i)\n",
    "                  for (i, s) in enumerate(weight_sizes)]\n",
    "\n",
    "        network_params = {\n",
    "            \"weights\": weights,\n",
    "            \"biases\": biases,\n",
    "        }\n",
    "\n",
    "        return network_params\n",
    "\n",
    "    def init_weights(self, shape):\n",
    "        return np.sqrt(6.0 / (shape[-2] + shape[-1])) * (2 * np.random.rand(*shape).astype(np.float32) - 1)\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        acts = inputs\n",
    "        for W, b in zip(self.params[\"weights\"], self.params[\"biases\"]):\n",
    "            hid = tf.matmul(acts, tf.nn.dropout(W, self.dropout_keep_prob)) + b\n",
    "            acts = tf.nn.relu(hid)\n",
    "        last_hidden = hid\n",
    "        return last_hidden\n",
    "\n",
    "class Graph():\n",
    " \n",
    "    def __init__(self, V, g):\n",
    "        self.V = V\n",
    "        self.graph  = g\n",
    " \n",
    "    def addEdge(self, v, w):\n",
    "        # Add w to v ist.\n",
    "        self.graph[v].append(w) \n",
    "        # Add v to w list.\n",
    "        self.graph[w].append(v) \n",
    " \n",
    "    # A recursive function that uses visited[] \n",
    "    # and parent to detect cycle in subgraph \n",
    "    # reachable from vertex v.\n",
    "    def isCyclicUtil(self, v, visited, parent):\n",
    " \n",
    "        # Mark current node as visited\n",
    "        visited[v] = True\n",
    " \n",
    "        # Recur for all the vertices adjacent \n",
    "        # for this vertex\n",
    "        for i in self.graph[v]:\n",
    "            # If an adjacent is not visited, \n",
    "            # then recur for that adjacent\n",
    "            if visited[i] == False:\n",
    "                if self.isCyclicUtil(i, visited, v) == True:\n",
    "                    return True\n",
    " \n",
    "            # If an adjacent is visited and not \n",
    "            # parent of current vertex, then there \n",
    "            # is a cycle.\n",
    "            elif i != parent:\n",
    "                return True\n",
    " \n",
    "        return False\n",
    " \n",
    "    # Returns true if the graph is a tree, \n",
    "    # else false.\n",
    "    def isTree(self):\n",
    "        # Mark all the vertices as not visited \n",
    "        # and not part of recursion stack\n",
    "        visited = [False] * self.V\n",
    " \n",
    "        # The call to isCyclicUtil serves multiple \n",
    "        # purposes. It returns true if graph reachable \n",
    "        # from vertex 0 is cyclcic. It also marks \n",
    "        # all vertices reachable from 0.\n",
    "        if self.isCyclicUtil(0, visited, -1) == True:\n",
    "            return False\n",
    " \n",
    "        # If we find a vertex which is not reachable\n",
    "        # from 0 (not marked by isCyclicUtil(), \n",
    "        # then we return false\n",
    "        for i in range(self.V):\n",
    "            if visited[i] == False:\n",
    "                return False\n",
    " \n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
